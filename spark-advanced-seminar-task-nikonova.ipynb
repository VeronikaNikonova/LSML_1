{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CGHGHkqE4rJw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm.notebook as tqdm\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3duPlU1fjxPz"
   },
   "source": [
    "# Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jovyan\n",
      " * Starting OpenBSD Secure Shell server sshd\n",
      "start-stop-daemon: unable to set gid to 0 (Operation not permitted)\n",
      "   ...fail!\n",
      " * sshd is running\n",
      "Starting namenodes on [localhost]\n",
      "localhost: Warning: Permanently added 'localhost' (ED25519) to the list of known hosts.\n",
      "localhost: namenode is running as process 165.  Stop it first and ensure /tmp/hadoop-jovyan-namenode.pid file is empty before retry.\n",
      "Starting datanodes\n",
      "localhost: Warning: Permanently added 'localhost' (ED25519) to the list of known hosts.\n",
      "localhost: datanode is running as process 278.  Stop it first and ensure /tmp/hadoop-jovyan-datanode.pid file is empty before retry.\n",
      "Starting secondary namenodes [e88e4034d828]\n",
      "e88e4034d828: Warning: Permanently added 'e88e4034d828' (ED25519) to the list of known hosts.\n",
      "e88e4034d828: secondarynamenode is running as process 489.  Stop it first and ensure /tmp/hadoop-jovyan-secondarynamenode.pid file is empty before retry.\n",
      "Starting resourcemanager\n",
      "resourcemanager is running as process 770.  Stop it first and ensure /tmp/hadoop-jovyan-resourcemanager.pid file is empty before retry.\n",
      "Starting nodemanagers\n",
      "localhost: Warning: Permanently added 'localhost' (ED25519) to the list of known hosts.\n",
      "localhost: nodemanager is running as process 882.  Stop it first and ensure /tmp/hadoop-jovyan-nodemanager.pid file is empty before retry.\n",
      "WARNING: Use of this script to start the MR JobHistory daemon is deprecated.\n",
      "WARNING: Attempting to execute replacement \"mapred --daemon start\" instead.\n",
      "3697 org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer\n",
      "770 org.apache.hadoop.yarn.server.resourcemanager.ResourceManager\n",
      "882 org.apache.hadoop.yarn.server.nodemanager.NodeManager\n",
      "165 org.apache.hadoop.hdfs.server.namenode.NameNode\n",
      "278 org.apache.hadoop.hdfs.server.datanode.DataNode\n",
      "3735 sun.tools.jps.Jps -lm\n",
      "489 org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode\n",
      "Configured Capacity: 1081101176832 (1006.85 GB)\n",
      "Present Capacity: 999363883008 (930.73 GB)\n",
      "DFS Remaining: 994479906816 (926.18 GB)\n",
      "DFS Used: 4883976192 (4.55 GB)\n",
      "DFS Used%: 0.49%\n",
      "Replicated Blocks:\n",
      "\tUnder replicated blocks: 0\n",
      "\tBlocks with corrupt replicas: 0\n",
      "\tMissing blocks: 0\n",
      "\tMissing blocks (with replication factor 1): 0\n",
      "\tLow redundancy blocks with highest priority to recover: 0\n",
      "\tPending deletion blocks: 0\n",
      "Erasure Coded Block Groups: \n",
      "\tLow redundancy block groups: 0\n",
      "\tBlock groups with corrupt internal blocks: 0\n",
      "\tMissing block groups: 0\n",
      "\tLow redundancy blocks with highest priority to recover: 0\n",
      "\tPending deletion blocks: 0\n",
      "\n",
      "-------------------------------------------------\n",
      "Live datanodes (1):\n",
      "\n",
      "Name: 127.0.0.1:9866 (localhost)\n",
      "Hostname: e88e4034d828\n",
      "Decommission Status : Normal\n",
      "Configured Capacity: 1081101176832 (1006.85 GB)\n",
      "DFS Used: 4883976192 (4.55 GB)\n",
      "Non DFS Used: 26744938496 (24.91 GB)\n",
      "DFS Remaining: 994479906816 (926.18 GB)\n",
      "DFS Used%: 0.45%\n",
      "DFS Remaining%: 91.99%\n",
      "Configured Cache Capacity: 0 (0 B)\n",
      "Cache Used: 0 (0 B)\n",
      "Cache Remaining: 0 (0 B)\n",
      "Cache Used%: 100.00%\n",
      "Cache Remaining%: 0.00%\n",
      "Xceivers: 0\n",
      "Last contact: Tue Mar 21 21:33:50 UTC 2023\n",
      "Last Block Report: Tue Mar 21 21:15:38 UTC 2023\n",
      "Num of Blocks: 298\n",
      "\n",
      "\n",
      "chmod: changing permissions of '/home/jovyan/jupyter.log': Operation not permitted\n",
      "chmod: changing permissions of '/home/jovyan/nginx.log': Operation not permitted\n",
      "chmod: changing permissions of '/home/jovyan/error.log': Operation not permitted\n",
      "chmod: changing permissions of '/home/jovyan/access.log': Operation not permitted\n"
     ]
    }
   ],
   "source": [
    "! /home/jovyan/start-hadoop.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "u566smRWkDOS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2023-03-21 21:33:59,112 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "# connect, context, session\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName='jupyter')\n",
    "\n",
    "from pyspark.sql import SparkSession, Row\n",
    "se = SparkSession(sc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1NJypwklF_Z"
   },
   "source": [
    "## Outbrain click prediction dataseet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twX4Yeez5Loj"
   },
   "source": [
    "https://www.kaggle.com/c/outbrain-click-prediction/data - you need to register here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Using cached kaggle-1.5.12-py3-none-any.whl\n",
      "Installing collected packages: kaggle\n",
      "  Attempting uninstall: kaggle\n",
      "    Found existing installation: kaggle 1.5.12\n",
      "    Uninstalling kaggle-1.5.12:\n",
      "      Successfully uninstalled kaggle-1.5.12\n",
      "Successfully installed kaggle-1.5.12\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/Kaggle/kaggle-api\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# instruction where to get ~/.kaggle/kaggle.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! mkdir -p ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/jovyan/.kaggle/kaggle.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/.kaggle/kaggle.json\n",
    "{\"username\":\"veronikanikonova\",\"key\":\"225b2f7497774e9f2ab634602a1e8cac\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "j4FsSCqe5CvG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (1.26.15)\n",
      "Collecting kaggle==1.5.3\n",
      "  Downloading kaggle-1.5.3.tar.gz (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m526.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting urllib3\n",
      "  Downloading urllib3-1.24.3-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.8/118.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle==1.5.3) (1.16.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kaggle==1.5.3) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle==1.5.3) (2.8.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle==1.5.3) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle==1.5.3) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle==1.5.3) (8.0.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle==1.5.3) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle==1.5.3) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle==1.5.3) (2.1.1)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.3-py3-none-any.whl size=64965 sha256=1b785b75938fd5114e20ba1967b1f52452f8fb912dfa4ce114f542235b6aa14f\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/ec/9c/e3/864c634d8176e91b4845d2a12f7ae6b1c035d56457f81452d0\n",
      "Successfully built kaggle\n",
      "Installing collected packages: urllib3, kaggle\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.15\n",
      "    Uninstalling urllib3-1.26.15:\n",
      "      Successfully uninstalled urllib3-1.26.15\n",
      "  Attempting uninstall: kaggle\n",
      "    Found existing installation: kaggle 1.5.13\n",
      "    Uninstalling kaggle-1.5.13:\n",
      "      Successfully uninstalled kaggle-1.5.13\n",
      "Successfully installed kaggle-1.5.3 urllib3-1.24.3\n",
      "Downloading page_views_sample.csv.zip to /home/jovyan/work\n",
      "100%|████████████████████████████████████████| 149M/149M [00:40<00:00, 4.47MB/s]\n",
      "100%|████████████████████████████████████████| 149M/149M [00:40<00:00, 3.86MB/s]\n",
      "Downloading events.csv.zip to /home/jovyan/work\n",
      "100%|████████████████████████████████████████| 478M/478M [01:57<00:00, 5.27MB/s]\n",
      "100%|████████████████████████████████████████| 478M/478M [01:57<00:00, 4.26MB/s]\n",
      "Downloading documents_topics.csv.zip to /home/jovyan/work\n",
      "100%|████████████████████████████████████████| 121M/121M [00:33<00:00, 4.15MB/s]\n",
      "100%|████████████████████████████████████████| 121M/121M [00:33<00:00, 3.81MB/s]\n",
      "Downloading documents_entities.csv.zip to /home/jovyan/work\n",
      "100%|████████████████████████████████████████| 126M/126M [00:51<00:00, 4.75MB/s]\n",
      "100%|████████████████████████████████████████| 126M/126M [00:51<00:00, 2.56MB/s]\n",
      "Downloading documents_meta.csv.zip to /home/jovyan/work\n",
      "100%|██████████████████████████████████████| 15.5M/15.5M [00:06<00:00, 4.07MB/s]\n",
      "100%|██████████████████████████████████████| 15.5M/15.5M [00:06<00:00, 2.47MB/s]\n",
      "Downloading clicks_test.csv.zip to /home/jovyan/work\n",
      "100%|███████████████████████████████████████▊| 135M/135M [00:41<00:00, 4.30MB/s]\n",
      "100%|████████████████████████████████████████| 135M/135M [00:42<00:00, 3.38MB/s]\n",
      "Downloading clicks_train.csv.zip to /home/jovyan/work\n",
      "100%|████████████████████████████████████████| 390M/390M [01:29<00:00, 4.00MB/s]\n",
      "100%|████████████████████████████████████████| 390M/390M [01:29<00:00, 4.59MB/s]\n",
      "Downloading documents_categories.csv.zip to /home/jovyan/work\n",
      " 99%|█████████████████████████████████████▌| 32.0M/32.3M [00:08<00:00, 4.65MB/s]\n",
      "100%|██████████████████████████████████████| 32.3M/32.3M [00:08<00:00, 3.81MB/s]\n",
      "Downloading promoted_content.csv.zip to /home/jovyan/work\n",
      " 80%|██████████████████████████████▏       | 2.00M/2.52M [00:00<00:00, 2.52MB/s]\n",
      "100%|██████████████████████████████████████| 2.52M/2.52M [00:01<00:00, 2.59MB/s]\n"
     ]
    }
   ],
   "source": [
    "! pip install -U urllib3 kaggle==1.5.3\n",
    "! kaggle competitions download -c outbrain-click-prediction -f page_views_sample.csv.zip\n",
    "! kaggle competitions download -c outbrain-click-prediction -f events.csv.zip \n",
    "! kaggle competitions download -c outbrain-click-prediction -f documents_topics.csv.zip \n",
    "! kaggle competitions download -c outbrain-click-prediction -f documents_entities.csv.zip \n",
    "! kaggle competitions download -c outbrain-click-prediction -f documents_meta.csv.zip \n",
    "! kaggle competitions download -c outbrain-click-prediction -f clicks_test.csv.zip\n",
    "! kaggle competitions download -c outbrain-click-prediction -f clicks_train.csv.zip\n",
    "! kaggle competitions download -c outbrain-click-prediction -f documents_categories.csv.zip\n",
    "! kaggle competitions download -c outbrain-click-prediction -f promoted_content.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  documents_entities.csv.zip\n",
      "  inflating: documents_entities.csv  \n",
      "\n",
      "Archive:  page_views_sample.csv.zip\n",
      "  inflating: page_views_sample.csv   \n",
      "\n",
      "Archive:  clicks_train.csv.zip\n",
      "  inflating: clicks_train.csv        \n",
      "\n",
      "Archive:  events.csv.zip\n",
      "  inflating: events.csv              \n",
      "\n",
      "Archive:  documents_categories.csv.zip\n",
      "  inflating: documents_categories.csv  \n",
      "\n",
      "Archive:  clicks_test.csv.zip\n",
      "  inflating: clicks_test.csv         \n",
      "\n",
      "Archive:  documents_topics.csv.zip\n",
      "  inflating: documents_topics.csv    \n",
      "\n",
      "Archive:  promoted_content.csv.zip\n",
      "  inflating: promoted_content.csv    \n",
      "\n",
      "Archive:  documents_meta.csv.zip\n",
      "  inflating: documents_meta.csv      \n",
      "\n",
      "9 archives were successfully processed.\n"
     ]
    }
   ],
   "source": [
    "! unzip '*.zip'\n",
    "! rm -rf *.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put: `page_views_sample.csv': File exists\n",
      "put: `events.csv': File exists\n",
      "put: `documents_topics.csv': File exists\n",
      "put: `documents_entities.csv': File exists\n",
      "put: `documents_meta.csv': File exists\n",
      "put: `clicks_test.csv': File exists\n",
      "put: `clicks_train.csv': File exists\n",
      "put: `documents_categories.csv': File exists\n",
      "put: `promoted_content.csv': File exists\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -put page_views_sample.csv\n",
    "! hdfs dfs -put events.csv\n",
    "! hdfs dfs -put documents_topics.csv\n",
    "! hdfs dfs -put documents_entities.csv\n",
    "! hdfs dfs -put documents_meta.csv\n",
    "! hdfs dfs -put clicks_test.csv\n",
    "! hdfs dfs -put clicks_train.csv\n",
    "! hdfs dfs -put documents_categories.csv\n",
    "! hdfs dfs -put promoted_content.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "V5Qx5EkolI_0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "|          uuid|document_id|timestamp|platform|geo_location|traffic_source|\n",
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "|1fd5f051fba643|        120| 31905835|       1|          RS|             2|\n",
      "|8557aa9004be3b|        120| 32053104|       1|       VN>44|             2|\n",
      "|c351b277a358f0|        120| 54013023|       1|       KR>12|             1|\n",
      "|8205775c5387f9|        120| 44196592|       1|       IN>16|             2|\n",
      "|9cb0ccd8458371|        120| 65817371|       1|   US>CA>807|             2|\n",
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df = se.read.csv(\"page_views_sample.csv\", header=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lUkB7pVjmnAB",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02154733eca6458798b5ada1100375f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicks_test\n",
      "+----------+------+\n",
      "|display_id| ad_id|\n",
      "+----------+------+\n",
      "|  16874594| 66758|\n",
      "|  16874594|150083|\n",
      "|  16874594|162754|\n",
      "+----------+------+\n",
      "\n",
      "clicks_train\n",
      "+----------+------+-------+\n",
      "|display_id| ad_id|clicked|\n",
      "+----------+------+-------+\n",
      "|         1| 42337|      0|\n",
      "|         1|139684|      0|\n",
      "|         1|144739|      1|\n",
      "+----------+------+-------+\n",
      "\n",
      "documents_categories\n",
      "+-----------+-----------+----------------+\n",
      "|document_id|category_id|confidence_level|\n",
      "+-----------+-----------+----------------+\n",
      "|    1595802|       1611|            0.92|\n",
      "|    1595802|       1610|            0.07|\n",
      "|    1524246|       1807|            0.92|\n",
      "+-----------+-----------+----------------+\n",
      "\n",
      "documents_entities\n",
      "+-----------+--------------------+-----------------+\n",
      "|document_id|           entity_id| confidence_level|\n",
      "+-----------+--------------------+-----------------+\n",
      "|    1524246|f9eec25663db4cd83...|0.672865314504701|\n",
      "|    1524246|55ebcfbdaff1d6f60...|0.399113728441297|\n",
      "|    1524246|839907a972930b17b...|0.392095749652966|\n",
      "+-----------+--------------------+-----------------+\n",
      "\n",
      "documents_meta\n",
      "+-----------+---------+------------+-------------------+\n",
      "|document_id|source_id|publisher_id|       publish_time|\n",
      "+-----------+---------+------------+-------------------+\n",
      "|    1595802|        1|         603|2016-06-05 00:00:00|\n",
      "|    1524246|        1|         603|2016-05-26 11:00:00|\n",
      "|    1617787|        1|         603|2016-05-27 00:00:00|\n",
      "+-----------+---------+------------+-------------------+\n",
      "\n",
      "documents_topics\n",
      "+-----------+--------+------------------+\n",
      "|document_id|topic_id|  confidence_level|\n",
      "+-----------+--------+------------------+\n",
      "|    1595802|     140|0.0731131601068925|\n",
      "|    1595802|      16|0.0594164867373976|\n",
      "|    1595802|     143|0.0454207537554526|\n",
      "+-----------+--------+------------------+\n",
      "\n",
      "events\n",
      "+----------+--------------+-----------+---------+--------+------------+\n",
      "|display_id|          uuid|document_id|timestamp|platform|geo_location|\n",
      "+----------+--------------+-----------+---------+--------+------------+\n",
      "|         1|cb8c55702adb93|     379743|       61|       3|   US>SC>519|\n",
      "|         2|79a85fa78311b9|    1794259|       81|       2|   US>CA>807|\n",
      "|         3|822932ce3d8757|    1179111|      182|       2|   US>MI>505|\n",
      "+----------+--------------+-----------+---------+--------+------------+\n",
      "\n",
      "page_views_sample\n",
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "|          uuid|document_id|timestamp|platform|geo_location|traffic_source|\n",
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "|1fd5f051fba643|        120| 31905835|       1|          RS|             2|\n",
      "|8557aa9004be3b|        120| 32053104|       1|       VN>44|             2|\n",
      "|c351b277a358f0|        120| 54013023|       1|       KR>12|             1|\n",
      "+--------------+-----------+---------+--------+------------+--------------+\n",
      "\n",
      "promoted_content\n",
      "+-----+-----------+-----------+-------------+\n",
      "|ad_id|document_id|campaign_id|advertiser_id|\n",
      "+-----+-----------+-----------+-------------+\n",
      "|    1|       6614|          1|            7|\n",
      "|    2|     471467|          2|            7|\n",
      "|    3|       7692|          3|            7|\n",
      "+-----+-----------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "tables = [\"clicks_test\", \"clicks_train\", \n",
    "          \"documents_categories\", \"documents_entities\", \"documents_meta\", \"documents_topics\", \n",
    "          \"events\", \"page_views_sample\", \"promoted_content\"]\n",
    "for name in tqdm.tqdm(tables):\n",
    "    df = se.read.csv(\"{}.csv\".format(name), header=True)\n",
    "    df.registerTempTable(name)\n",
    "    print(name)\n",
    "    df.limit(3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hK93Ci6Rj51c"
   },
   "source": [
    "## Evaluation Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Jf8VBI-j530"
   },
   "source": [
    "Data: outbrain click prediction\n",
    "\n",
    "Tasks:\n",
    "Using Spark RDD, DataFrame API and Python, calculate:\n",
    "\n",
    "**1**. Top 10 most visited document_ids in the page_views_sample log\n",
    "\n",
    "**2**. How many users have at least 2 different traffic_sources in the page_views_sample log (note the value is not a count, it's an encoded enum)\n",
    "\n",
    "**3***. Top 10 most visited topic_ids in page_views_sample log (use documents_topics table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submission format is the result.json json file with top_10_documents, users and top_10_topics keys.\n",
    "For TOP-10 results, the answer must be written in the form of a sheet ordered from TOP-1 to TOP-10 with an id.\n",
    "\n",
    "result.json example:\n",
    "\n",
    "    {\n",
    "        \"top_10_documents\": [\n",
    "            111,\n",
    "            222,\n",
    "            333,\n",
    "            ...,\n",
    "            1010\n",
    "        ],\n",
    "        \"users\": 10000,\n",
    "        \"top_10_topics\": [\n",
    "            11,\n",
    "            22,\n",
    "            33,\n",
    "            ...,\n",
    "            101\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:====================================================>   (30 + 2) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|document_id|   cnt|\n",
      "+-----------+------+\n",
      "|    1811567|429551|\n",
      "|        234|179692|\n",
      "|      42744|156231|\n",
      "|    1858440|112140|\n",
      "|    1780813|109624|\n",
      "|      60164|104941|\n",
      "|    1790442| 91420|\n",
      "|    1877626| 80309|\n",
      "|    1821895| 79956|\n",
      "|     732651| 74630|\n",
      "+-----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Task 1. Variant 1 (using sql)\n",
    "top_10_docs = se.sql(\"\"\"\n",
    "select\n",
    "    document_id, \n",
    "    count(*) as cnt \n",
    "from page_views_sample \n",
    "group by document_id \n",
    "order by cnt desc\n",
    "\"\"\")\n",
    "top_10_docs.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:======================================================> (31 + 1) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|document_id|   cnt|\n",
      "+-----------+------+\n",
      "|    1811567|429551|\n",
      "|        234|179692|\n",
      "|      42744|156231|\n",
      "|    1858440|112140|\n",
      "|    1780813|109624|\n",
      "|      60164|104941|\n",
      "|    1790442| 91420|\n",
      "|    1877626| 80309|\n",
      "|    1821895| 79956|\n",
      "|     732651| 74630|\n",
      "+-----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# Task 1. Variant 2 (using DataFrame)\n",
    "page_views = se.table(\"page_views_sample\")\n",
    "(\n",
    "  page_views\n",
    "    .groupby(\"document_id\")\n",
    "    .agg(F.count(\"document_id\").alias(\"cnt\"))\n",
    "    .orderBy(desc(\"cnt\"))\n",
    "    .limit(10)\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:======================================================> (33 + 1) / 34]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|count(DISTINCT uuid)|\n",
      "+--------------------+\n",
      "|               98080|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Task 2. Variant 1 (using sql)\n",
    "users_diff_ts = se.sql(\"\"\"\n",
    "select\n",
    "    count(distinct pvs_1.uuid) \n",
    "from page_views_sample as pvs_1 \n",
    "cross join page_views_sample as pvs_2 \n",
    "where pvs_1.uuid = pvs_2.uuid and pvs_1.traffic_source <> pvs_2.traffic_source\n",
    "\"\"\")\n",
    "users_diff_ts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:====================================================>   (32 + 2) / 34]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|users_number|\n",
      "+------------+\n",
      "|       98080|\n",
      "+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Task 2. Variant 2 (using sql)\n",
    "users_diff_ts = se.sql(\"\"\"\n",
    "select\n",
    "    count(*) as users_number\n",
    "from(\n",
    "    select\n",
    "        uuid,\n",
    "        count(distinct traffic_source) as cnt\n",
    "    from page_views_sample \n",
    "    group by uuid\n",
    "    having cnt > 1\n",
    ")\n",
    "\"\"\")\n",
    "users_diff_ts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98080"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 2. Variant 3 (using DataFrame)\n",
    "(\n",
    "  page_views\n",
    "    .groupby(\"uuid\")\n",
    "    .agg(F.countDistinct(\"traffic_source\").alias(\"cnt\"))\n",
    "    .where(\"cnt > 1\")\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 80:====================================================>   (32 + 2) / 34]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|topic_id|    cnt|\n",
      "+--------+-------+\n",
      "|      20|1429253|\n",
      "|      16|1425838|\n",
      "|     216|1160563|\n",
      "|     136|1099382|\n",
      "|     140| 971983|\n",
      "|     143| 919136|\n",
      "|      36| 855793|\n",
      "|      97| 839328|\n",
      "|       8| 819599|\n",
      "|     269| 727145|\n",
      "+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Task 3. Variant 1 (using sql)\n",
    "top_topics = se.sql(\"\"\"\n",
    "select\n",
    "    dt.topic_id, \n",
    "    count(*) as cnt \n",
    "from page_views_sample as pvs_1 \n",
    "join documents_topics as dt \n",
    "on pvs_1.document_id=dt.document_id \n",
    "group by dt.topic_id \n",
    "order by cnt desc\n",
    "\"\"\")\n",
    "top_topics.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 89:======================================================> (33 + 1) / 34]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|topic_id|    cnt|\n",
      "+--------+-------+\n",
      "|      20|1429253|\n",
      "|      16|1425838|\n",
      "|     216|1160563|\n",
      "|     136|1099382|\n",
      "|     140| 971983|\n",
      "|     143| 919136|\n",
      "|      36| 855793|\n",
      "|      97| 839328|\n",
      "|       8| 819599|\n",
      "|     269| 727145|\n",
      "+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Task 3. Variant 2 (using DataFrame)\n",
    "documents_topics = se.table(\"documents_topics\")\n",
    "(\n",
    "  page_views\n",
    "    .join(documents_topics, page_views.document_id == documents_topics.document_id, 'inner')\n",
    "    .groupby(\"topic_id\")\n",
    "    .agg(F.count(\"topic_id\").alias(\"cnt\"))\n",
    "    .orderBy(desc(\"cnt\"))\n",
    "    .limit(10)\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = json.dumps({\n",
    "    \"top_10_documents\": [\n",
    "        1811567,\n",
    "        234,\n",
    "        42744,\n",
    "        1858440,\n",
    "        1780813,\n",
    "        60164,\n",
    "        1790442,\n",
    "        1877626,\n",
    "        1821895,\n",
    "        732651        \n",
    "    ],\n",
    "    \"users\": 98080,\n",
    "    \"top_10_topics\": [\n",
    "        20,\n",
    "        16,\n",
    "        216,\n",
    "        136,\n",
    "        140,\n",
    "        143,\n",
    "        36,\n",
    "        97, \n",
    "        8, \n",
    "        269\n",
    "    ]\n",
    "})\n",
    "with open('result.json', 'w') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "!curl -F file=@result.json \"51.250.54.133:80/MDS-LSML1/veronika_nikon/w4/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "spark_seminar (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
